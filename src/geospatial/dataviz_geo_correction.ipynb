{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-ceremony",
   "metadata": {
    "id": "catholic-ceremony"
   },
   "source": [
    "# Visualisation de données géo-spatiales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-blair",
   "metadata": {
    "id": "caring-blair"
   },
   "source": [
    "On se propose ici d'analyser le déplacement de 182 utilisateurs équipés de balises GPS. Ce projet est nommé Geolife et est porté par Microsoft.\n",
    "\n",
    "Le TP consiste à vous familiariser avec les données géo-spatiales et la librairie Kepler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-editing",
   "metadata": {
    "id": "temporal-editing"
   },
   "source": [
    "## I. Import des données\n",
    "Afin de travailler sur un jeu de données propre pour l'analyse, certaines étapes de préprocessing sont nécessaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-inside",
   "metadata": {
    "id": "experimental-inside"
   },
   "source": [
    "a) Importer les données dans un DataFrame `df`\n",
    "\n",
    "Nous utiliserons un extract fourni : **geolife_data_500k_sample.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-magnitude",
   "metadata": {
    "id": "vocational-magnitude"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/workspace/data/geolife_data_500k_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-doctor",
   "metadata": {
    "id": "bibliographic-doctor"
   },
   "source": [
    "b) Exécutez le code suivant pour renommer les colonnes, changer le format de la colonne Date_Time et enfin ne garder que les positions latitude / longitude qui sont non nulles. Ces étapes sont classiques lors de la manipulation de ce genre de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-bulgarian",
   "metadata": {
    "id": "useful-bulgarian"
   },
   "outputs": [],
   "source": [
    "# renommer les colonnes\n",
    "df.rename({'Id_user': 'id', 'Date_Time': 'datetime', 'Id_perc': 'id_traj'}, axis=1, inplace=True)\n",
    "\n",
    "# conversion de la date en string en objet datetime64\n",
    "DATETIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format=DATETIME_FORMAT)\n",
    "\n",
    "# Supression des lignes sans géolocalisation\n",
    "df = df[(~df['Latitude'].isnull()) & (~df['Longitude'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-clause",
   "metadata": {
    "id": "cooked-clause"
   },
   "source": [
    "c) Pour le TD, on ne va garder que les trajectoires des utilisateurs entre 1er Septembre 2009 et le 1er Octobre 2009 exclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-consortium",
   "metadata": {
    "id": "understood-consortium"
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df = df[(df['datetime'] >= '2009-09-01 00:00:00') & (df['datetime'] < '2009-10-01 00:00:00')]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-monroe",
   "metadata": {
    "id": "nonprofit-monroe"
   },
   "source": [
    "d) Afficher le nombre de points par id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-viewer",
   "metadata": {
    "id": "bronze-viewer"
   },
   "outputs": [],
   "source": [
    "# conversion de l'id en string (utile pour que kepler l'interprete en string)\n",
    "df['id'] = df['id'].apply(lambda x: 'user_' + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-campus",
   "metadata": {
    "id": "independent-campus"
   },
   "outputs": [],
   "source": [
    "df.id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-seeker",
   "metadata": {
    "id": "after-seeker"
   },
   "source": [
    "# II. Visualisation basique avec Kepler\n",
    "Cette partie a pour but de prendre en main les fonctionnements de bases de l'outil de visualisation Kepler afin d'analyser les données de ces trajectoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-mandate",
   "metadata": {
    "id": "incredible-mandate"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from keplergl import KeplerGl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-netscape",
   "metadata": {
    "id": "changed-netscape"
   },
   "source": [
    "a) Affichez les données brutes sur Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf98bdc-f72a-46f8-b569-1cf0ca5adfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.output_result { max-width:100% !important; }</style>\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-south",
   "metadata": {
    "id": "actual-south"
   },
   "outputs": [],
   "source": [
    "mymap = KeplerGl(data={'df': df})\n",
    "#======= special correction ========\n",
    "#with open('/workspace/data/ma_config_correction.json', \"r\") as f:\n",
    "#    conf = json.load(f)\n",
    "#mymap.config = conf\n",
    "#===================================\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-forest",
   "metadata": {
    "id": "eleven-forest"
   },
   "source": [
    "b) Attribuez une couleur par ID depuis l'interface de Kepler et afficher la legende"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-watson",
   "metadata": {
    "id": "sitting-watson"
   },
   "source": [
    "c) Utiliser les filtres pour filtrer sur le temps et afficher la timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-orange",
   "metadata": {
    "id": "antique-orange"
   },
   "source": [
    "d) Utilisez les filtres pour filtrer sur l'ID = user_85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-resistance",
   "metadata": {
    "id": "quality-resistance"
   },
   "source": [
    "e) Masquez le layer 'Point' et ajouter un layer de type 'Heatmap'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-fifteen",
   "metadata": {
    "id": "informational-fifteen"
   },
   "source": [
    "f) Affichez la configuration actuelle de Kepler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-merchant",
   "metadata": {
    "id": "scientific-merchant",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mymap.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-liberty",
   "metadata": {
    "id": "powerful-liberty"
   },
   "source": [
    "g) Enregistrez votre configuration de Kepler dans un fichier nommé 'ma_config.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-pillow",
   "metadata": {
    "id": "civilian-pillow"
   },
   "outputs": [],
   "source": [
    "with open('/workspace/data/ma_config.json', \"w\") as f:\n",
    "    f.write(json.dumps(mymap.config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-possession",
   "metadata": {
    "id": "marked-possession"
   },
   "source": [
    "h) Rechargez le fichier de config 'ma_config.json' puis réafficher Kepler (via KeplerGL) en utilisant cette configuration.\n",
    "\n",
    "Vous devriez alors avoir un Kepler avec uniquement une heatmap du user_85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-fellowship",
   "metadata": {
    "id": "narrow-fellowship"
   },
   "outputs": [],
   "source": [
    "with open('/workspace/data/ma_config.json', \"r\") as f:\n",
    "    conf = json.load(f)\n",
    "\n",
    "mymap = KeplerGl(height=600, data={'df': df})\n",
    "mymap.config = conf\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-federal",
   "metadata": {
    "id": "fixed-federal"
   },
   "source": [
    "# III. Visualisation avancée avec Kepler\n",
    "Cette partie permet de prendre en main des structures de données plus poussées telles que les trajectoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-milwaukee",
   "metadata": {
    "id": "bulgarian-milwaukee"
   },
   "outputs": [],
   "source": [
    "from datetime import timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-logging",
   "metadata": {
    "id": "hawaiian-logging"
   },
   "source": [
    "a) Créez à partir des points, un seul dataframe contenant tous les segments de trajet pour chaque ID.\n",
    "\n",
    "\n",
    "L'objectif est de créer une ligne par segment de déplacement. Il y a donc une latitude/longitude pour le point de départ et une autre pour le point d'arrivé. Le dataset final doit etre constitué de tous ces segments pour constituer l'ensemble des déplacements de l'individus, réalisés dans l'ordre chronologique.\n",
    "\n",
    "Complétez le code ci-dessous pour y parvenir.\n",
    "\n",
    "Indices : vous pouvez utiliser la fonction [shift](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html) sur la variables `rows` des éléments groupés pour reconstruire un dataframe avec un point source et un point destination sur une même ligne avec les dates respectives.\n",
    "Ce que je veux : une ligne = un segment de trajectoire avec un point source et un point destination\n",
    "\n",
    "Exemple :\n",
    "```python\n",
    "df_points = pd.DataFrame([['lat_1', 'lon_1'],\n",
    "                          ['lat_2', 'lon_2'],\n",
    "                          ['lat_3', 'lon_3']],\n",
    "                         columns=['Latitude', 'Longitude'])\n",
    "\n",
    "# résultat\n",
    "source_lat, source_lon, destination_lat, destination_lon\n",
    "lat_1,      lon_1,      lat_2,           lon_2\n",
    "lat_2,      lon_2,      lat_3,           lon_3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-sweet",
   "metadata": {
    "id": "massive-sweet"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-farmer",
   "metadata": {
    "id": "young-farmer"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "segments = []\n",
    "for idx, rows in df.sort_values('datetime', ascending=True).groupby(['id', 'id_traj']):\n",
    "    id_user = idx[0]\n",
    "    id_traj = idx[1]\n",
    "    if len(rows) > 2:\n",
    "        a = rows.copy()\n",
    "        a.rename({'Latitude': 'source_lat', 'Longitude': 'source_lon', 'Altitude': 'source_alt', 'datetime': 'datetime_start'}, axis=1, inplace=True)\n",
    "        b = rows.shift(-1)\n",
    "        b.rename({'Latitude': 'dest_lat', 'Longitude': 'dest_lon', 'Altitude': 'dest_alt', 'datetime': 'datetime_end'}, axis=1, inplace=True)\n",
    "        pairs = pd.concat([a, b], axis=1)\n",
    "        pairs.dropna(subset=['dest_lat'], inplace=True) # pour supprimer la dernière paire qui contient forcément un nan\n",
    "        pairs = pairs.loc[:, ~pairs.columns.duplicated()] # pour supprimer les colonnes duppliquées avec le même nom\n",
    "        segments.append(pairs)\n",
    "\n",
    "df_segments = pd.concat(segments)\n",
    "print(df_segments.shape)\n",
    "df_segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-burst",
   "metadata": {
    "id": "fourth-burst"
   },
   "source": [
    "**Affichez le nombre de trajectoires par id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-sensitivity",
   "metadata": {
    "id": "animal-sensitivity"
   },
   "outputs": [],
   "source": [
    "df_segments.groupby('id')['id_traj'].nunique()\n",
    "df_segments.groupby('id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-variation",
   "metadata": {
    "id": "educated-variation"
   },
   "source": [
    "b) Créez un geojson à partir du dataframe de segments à l'aide de la fonction `get_traj` en exécutant le code ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-liabilities",
   "metadata": {
    "id": "immediate-liabilities"
   },
   "outputs": [],
   "source": [
    "def get_traj(df):\n",
    "    df = df.sort_values('datetime', ascending=True)\n",
    "    features = []\n",
    "    for idx, rows in df.groupby(['id', 'id_traj']):\n",
    "        trajs = []\n",
    "        for i, row in rows.iterrows():\n",
    "            trajs.append([\n",
    "                row['Longitude'],\n",
    "                row['Latitude'],\n",
    "                0,\n",
    "                int(row['datetime'].replace(tzinfo=timezone.utc).timestamp())\n",
    "            ])\n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": {\n",
    "                \"ID\": 'idx_' + str(idx[0]) + '_traj_' + str(idx[1])\n",
    "            },\n",
    "            \"geometry\": {\n",
    "                \"type\": \"LineString\",\n",
    "                \"coordinates\": trajs\n",
    "            }\n",
    "        })\n",
    "    trajs_geojson = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "    return json.dumps(trajs_geojson)\n",
    "\n",
    "trajs = get_traj(df)\n",
    "trajs[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-transition",
   "metadata": {
    "id": "aggregate-transition"
   },
   "source": [
    "c) Chargez le dataframe de segments (`df_segments`) et le geojson de trajets (`trajs`) en utilisant la fonction [add_data](https://docs.kepler.gl/docs/keplergl-jupyter#2-add-data) de Kepler.\n",
    "\n",
    "Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-sunday",
   "metadata": {
    "id": "hairy-sunday"
   },
   "outputs": [],
   "source": [
    "mymap = KeplerGl(height=600, data={'df_segments': df_segments})\n",
    "mymap.add_data(trajs, name='trajectory')\n",
    "#======= special correction ========\n",
    "with open('/workspace/data/ma_config_correction_2.json', \"r\") as f:\n",
    "    conf = json.load(f)\n",
    "mymap.config = conf\n",
    "#===================================\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-three",
   "metadata": {
    "id": "popular-three"
   },
   "source": [
    "d) Affichez le layer de type 'Line' et attribuez une couleur par ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-circumstances",
   "metadata": {
    "id": "optional-circumstances"
   },
   "source": [
    "e) Depuis l'onglet 'Interactions' de Kepler, ajouter dans le tooltip l'information 'source_lat' et 'source_lon'.\n",
    "\n",
    "Passez ensuite la souris sur une des lignes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-concentration",
   "metadata": {
    "id": "massive-concentration"
   },
   "source": [
    "f) Affichez le layer 'Arc' et la vue en 3D et attribuez une couleur par ID\n",
    "\n",
    "Comparez le résultat avec le layer de type 'Line'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-valve",
   "metadata": {
    "id": "curious-valve"
   },
   "source": [
    "g) Masquez les layer 'Line' et 'Arc' et affichez le layer 'Trip'\n",
    "\n",
    "Regardez à la date du 09/02/2009 à 7h à vitesse 0,001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-discharge",
   "metadata": {
    "id": "conceptual-discharge"
   },
   "source": [
    "# IV. Clustering\n",
    "Cette partie permet d'appliquer des techniques de machine learning non supervisé afin de regrouper les lieux d'intérets (cluster) à partir des données géospatiales.\n",
    "\n",
    "Extraire des lieux d'intéret permet ensuite d'inférer des zones de vies ou des lieux habituels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-simulation",
   "metadata": {
    "id": "hispanic-simulation"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import pi\n",
    "from functools import partial\n",
    "\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import unary_union\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-surrey",
   "metadata": {
    "id": "liquid-surrey"
   },
   "source": [
    "a) Convertissez les colonnes 'Latitude' et 'Longitude' en radians à l'aide de la librairie [numpy](https://numpy.org/doc/stable/reference/generated/numpy.radians.html).\n",
    "\n",
    "Vous nommerez les colonnes résultantes `Latitude_rad` et `Longitude_rad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-madness",
   "metadata": {
    "id": "suspended-madness"
   },
   "outputs": [],
   "source": [
    "df['Latitude_rad'] = df['Latitude'].apply(np.radians)\n",
    "df['Longitude_rad'] = df['Longitude'].apply(np.radians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-thermal",
   "metadata": {
    "id": "variable-thermal"
   },
   "source": [
    "b) Les hyperparamètres suivants permettent de préciser une distance en mètre comme paramètre du clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-aquarium",
   "metadata": {
    "id": "celtic-aquarium"
   },
   "outputs": [],
   "source": [
    "MAX_DIST_M = 20\n",
    "MIN_SAMPLES = 15\n",
    "\n",
    "EARTH_RADIUS = 6371088 # mètres\n",
    "\n",
    "def m2rad(dist):\n",
    "    return dist / EARTH_RADIUS\n",
    "\n",
    "dbscan_args = {\n",
    "    'eps': m2rad(MAX_DIST_M),\n",
    "    'min_samples': MIN_SAMPLES,\n",
    "    'metric': 'haversine'\n",
    "}\n",
    "dbscan_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-return",
   "metadata": {
    "id": "immune-return"
   },
   "source": [
    "c) Entrainez l'algorithme de clustering dbscan sur les colonnes `Latitude_rad` et `Longitude_rad`.\n",
    "\n",
    "On pourra passer les arguments `dbscan_args` à la fonction DBSCAN en mettant `**dbscan_args`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-arthritis",
   "metadata": {
    "id": "blessed-arthritis"
   },
   "outputs": [],
   "source": [
    "clustering = DBSCAN(**dbscan_args)\n",
    "clustering.fit(df[['Latitude_rad', 'Longitude_rad']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-launch",
   "metadata": {
    "id": "arabic-launch"
   },
   "source": [
    "d) Ajoutez une colonne 'cluster' contenant les ids des clusters.\n",
    "\n",
    "Indice : utiliser l'agument 'labels_'\n",
    "\n",
    "Affichez le nombre de points par cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-portable",
   "metadata": {
    "id": "binary-portable"
   },
   "outputs": [],
   "source": [
    "df['cluster'] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-trademark",
   "metadata": {
    "id": "loving-trademark"
   },
   "outputs": [],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-accuracy",
   "metadata": {
    "id": "boolean-accuracy"
   },
   "source": [
    "e) Visualisez les points associés aux cluster avec Kepler, avec une couleur par 'cluster'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-roulette",
   "metadata": {
    "id": "conservative-roulette"
   },
   "outputs": [],
   "source": [
    "KeplerGl(height=600, data={'df_cluster': df})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-service",
   "metadata": {
    "id": "australian-service"
   },
   "source": [
    "f) Construction de l'enveloppe des clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-extra",
   "metadata": {
    "id": "convinced-extra"
   },
   "source": [
    "**Ajoutez une colonne 'geometry' composé d'un polygone de cercle ayant un rayon similaire au paramètre 'eps' du DBSCAN en exécutant le code ci-dessous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-capability",
   "metadata": {
    "id": "registered-capability"
   },
   "outputs": [],
   "source": [
    "#========= Version simplifiée, sans projection =========\n",
    "df['geometry'] = df.apply(lambda row: Point(row['Longitude'], row['Latitude']).buffer(m2rad(MAX_DIST_M) * (180 / pi)), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sgDMBSKmkFKp",
   "metadata": {
    "id": "sgDMBSKmkFKp"
   },
   "outputs": [],
   "source": [
    "#df['geometry'] = df['geometry'].apply(lambda poly: str(poly) if not isinstance(poly, str) else poly)\n",
    "#KeplerGl(height=600, data={'df_cluster': df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-times",
   "metadata": {
    "id": "toxic-times"
   },
   "outputs": [],
   "source": [
    "#========= OPTIONNEL : prise en compte de la projection WGS84 =========\n",
    "#def get_circle_from_point_with_projection(lat, lon, radius):\n",
    "#    # Shapely point\n",
    "#    point = Point(lon, lat)\n",
    "#    # Local azimuthal projection (planar)\n",
    "#    local_az_proj = f\"+proj=aeqd +R=6371000 +units=m +lat_0={point.y} +lon_0={point.x}\"\n",
    "#    # Transfrom WGS84 data to local frame of reference\n",
    "#    wgs84_to_aeqd = partial(\n",
    "#        pyproj.transform,\n",
    "#        pyproj.Proj('+proj=longlat +datum=WGS84 +no_defs'),\n",
    "#        pyproj.Proj(local_az_proj)\n",
    "#    )\n",
    "#    # Transfrom local frame of reference data to WGS84\n",
    "#    aeqd_to_wgs84 = partial(\n",
    "#        pyproj.transform,\n",
    "#        pyproj.Proj(local_az_proj),\n",
    "#        pyproj.Proj('+proj=longlat +datum=WGS84 +no_defs'),\n",
    "#    )\n",
    "#    # Transform point\n",
    "#    point_transformed = transform(wgs84_to_aeqd, point)\n",
    "#    buffer = point_transformed.buffer(radius)\n",
    "#    buffer_wgs84 = transform(aeqd_to_wgs84, buffer)\n",
    "#    return buffer_wgs84\n",
    "#\n",
    "#df['geometry'] = df.apply(lambda row: get_circle_from_point_with_projection(row['Longitude'], row['Latitude'], m2rad(MAX_DIST_M) * (180 / pi)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-dining",
   "metadata": {
    "id": "quality-dining"
   },
   "source": [
    "**Dans un nouveau DataFrame `clusters_poly`, Fusionnez chaque polygon de cercle d'un cluster en un seul polygone pour créer une enveloppe pour chaque cluster.**\n",
    "\n",
    "Indice : utilisez 'unary_union' de 'shapely.ops' préalablement importée pour construire un polygone résultant de l'union des polygones de cercles d'un cluster. Il faudra grouper par la colonne `cluster` et appliquer cette fonction à la colonne `geometry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-discussion",
   "metadata": {
    "id": "yellow-discussion"
   },
   "outputs": [],
   "source": [
    "clusters_poly = df.groupby('cluster')['geometry'].apply(unary_union).reset_index()\n",
    "clusters_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-retrieval",
   "metadata": {
    "id": "electric-retrieval"
   },
   "source": [
    "**Filtrez le DataFrame `cluster_poly` pour éliminer le cluster -1 de l'algorithme dbscan.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-circle",
   "metadata": {
    "id": "fleet-circle"
   },
   "outputs": [],
   "source": [
    "clusters_poly = clusters_poly[clusters_poly['cluster'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-portrait",
   "metadata": {
    "id": "electoral-portrait"
   },
   "source": [
    "**Convertissez la colonne geometry du DataFrame `cluster_poly` en string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-nancy",
   "metadata": {
    "id": "afraid-nancy"
   },
   "outputs": [],
   "source": [
    "clusters_poly['geometry'] = clusters_poly['geometry'].apply(lambda poly: str(poly) if not isinstance(poly, str) else poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-louis",
   "metadata": {
    "id": "committed-louis"
   },
   "source": [
    "g) Affichez les polygones correspondants aux enveloppes avec le mode 'polygon', avec une couleur par polygone de cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-today",
   "metadata": {
    "id": "fresh-today"
   },
   "outputs": [],
   "source": [
    "KeplerGl(height=600, data={'df_cluster': clusters_poly})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-chancellor",
   "metadata": {
    "id": "significant-chancellor"
   },
   "source": [
    "h) A quoi correspondent les clusters ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-cuisine",
   "metadata": {
    "id": "national-cuisine"
   },
   "source": [
    "### BONUS :\n",
    "- Faire varier les paramètres 'epsilon' et 'min_sample' de l'algorithme. Que remarquez vous ? Quelles sont d'après vous les limites d'une approche DBSCAN ?\n",
    "- Pour chaque cluster, appliquer un ratio heure de nuits / heures total via des tranches horaires sur les points présents dans ce cluster. Visualiser ensuite les polygones des clusters avec une couleur variant du rouge au bleu en fonction du ratio. Bleu pour la nuit, rouge pour le jour."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
